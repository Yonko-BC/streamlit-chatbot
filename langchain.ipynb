{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(openai_api_key = openai_api_key,temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The meaning of life is subjective and can vary depending on individual beliefs and values. Some may believe that the purpose of life is to find happiness and fulfillment, while others may believe that the purpose of life is to learn and grow spiritually. Ultimately, the meaning of life is up to each individual to determine for themselves.\n"
     ]
    }
   ],
   "source": [
    "prompt=\"what is the meaning of life?\"\n",
    "\n",
    "try:\n",
    "    print(llm.predict(prompt))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonko/Desktop/learnLLm/Langchain/Tp-1/venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm_huggingFaceHub=HuggingFaceHub(repo_id=\"google/flan-t5-base\",model_kwargs={\"temperature\":0.6,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the idea of a business being a monopoly on the market\n"
     ]
    }
   ],
   "source": [
    "print(llm_huggingFaceHub.predict(\"write me a poem about business AI\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is John and I am 30 years old. give a short presentation about myself'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=[\"name\",\"age\"],template=\"My name is {name} and I am {age} years old. give a short presentation about myself\")\n",
    "\n",
    "prompt_template.format(name=\"John\",age=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHello everyone, my name is John and I am 30 years old. I am currently living in New York City and working as a software engineer. I have a passion for technology and have been working in the industry for the past seven years. I also enjoy travelling and exploring new places. In my free time, I like to read books, watch movies, and play sports. I am a friendly and outgoing person who loves to meet new people.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
    "\n",
    "chain.run({\"name\":\"John\",\"age\":30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multiple chains using simple sequencial chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=[\"country\"],template=\"The capital of {country} is\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=[\"capital\"],template=\"some famous places in {capital} are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_chain = LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Eiffel Tower\\n2. Louvre Museum\\n3. Notre Dame Cathedral\\n4. Arc de Triomphe\\n5. Champs-Elysees\\n6. Sacre-Coeur\\n7. Centre Pompidou\\n8. Luxembourg Gardens\\n9. Palace of Versailles\\n10. Montmartre'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "\n",
    "chain.run(\"France\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequencial chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_template = PromptTemplate(input_variables=[\"country\"],template=\"The capital of {country} is\")\n",
    "\n",
    "capital_chain = LLMChain(llm=llm,prompt=capital_template,output_key=\"capital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template = PromptTemplate(input_variables=[\"capital\"],template=\"some famous places in {capital} are\")\n",
    "famous_chain = LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'morocco',\n",
       " 'capital': ' Rabat.',\n",
       " 'places': '\\n\\n1. Hassan Tower\\n2. Kasbah of the Udayas\\n3. Mausoleum of Mohammed V\\n4. Chellah\\n5. Royal Palace of Rabat\\n6. Andalusian Gardens\\n7. Galerie Nationale de Rabat\\n8. Tour Hassan\\n9. Rabat Archaeological Museum\\n10. Oudaya Museum'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain=SequentialChain(chains=[capital_chain,famous_chain],input_variables=[\"country\"],output_variables=[\"capital\",\"places\"])\n",
    "\n",
    "chain({\"country\":\"morocco\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodels with OpenAI GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chat=ChatOpenAI(openai_api_key=openai_api_key,temperature=0.6,model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the AI go into business?\\n\\nBecause it wanted to make some \"byte\"-ful profits!')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm_chat([\n",
    "    SystemMessage(content=\"you are a comedian AI Assistant\"),\n",
    "    HumanMessage(content=\"please tell me a joke about business and AI\"),  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates + LLM + Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaseparatedOutputParser(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. when the user gives you an input , you should generate 5 words synonym of the input with a comma separator list\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chatPrompt = ChatPromptTemplate.from_messages([(\"system\",template),(\"human\",human_template)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatPrompt|llm_chat|CommaseparatedOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intelligent', ' clever', ' sharp', ' astute', ' knowledgeable']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"smart\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
